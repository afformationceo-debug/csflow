#!/usr/bin/env tsx
/**
 * CSV ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸
 *
 * ì‚¬ìš©ë²•:
 * 1. ê±°ë˜ì²˜ CSV: npm run migrate:csv -- --type tenants --file tenants.csv
 * 2. ì§€ì‹ë² ì´ìŠ¤ CSV: npm run migrate:csv -- --type knowledge --file knowledge.csv
 *
 * CSV í˜•ì‹:
 *
 * tenants.csv:
 * name,name_en,specialty,default_language,system_prompt
 * "íë§ì•ˆê³¼","Healing Eye Clinic","ophthalmology","ja","[í”„ë¡¬í”„íŠ¸]"
 *
 * knowledge.csv:
 * tenant_name,title,content,category,tags
 * "íë§ì•ˆê³¼","ë¼ì‹ ìˆ˜ìˆ  ì•ˆë‚´","ë¼ì‹ ìˆ˜ìˆ ì€...","ì‹œìˆ ì•ˆë‚´","ë¼ì‹,ìˆ˜ìˆ ,ì•ˆê³¼"
 */

import { createClient } from "@supabase/supabase-js";
import { parse } from "csv-parse/sync";
import * as fs from "fs";
import * as path from "path";
import OpenAI from "openai";

// í™˜ê²½ë³€ìˆ˜ ì²´í¬
const SUPABASE_URL = process.env.NEXT_PUBLIC_SUPABASE_URL;
const SUPABASE_SERVICE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

if (!SUPABASE_URL || !SUPABASE_SERVICE_KEY) {
  console.error("âŒ Supabase í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
  process.exit(1);
}

if (!OPENAI_API_KEY) {
  console.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
  process.exit(1);
}

const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_KEY);
const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

/**
 * í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í•  (500ì ê¸°ì¤€)
 */
function chunkText(text: string, maxLength = 500): string[] {
  const chunks: string[] = [];
  let currentChunk = "";

  const sentences = text.split(/[.!?]\s+/);

  for (const sentence of sentences) {
    if ((currentChunk + sentence).length > maxLength && currentChunk) {
      chunks.push(currentChunk.trim());
      currentChunk = sentence;
    } else {
      currentChunk += (currentChunk ? " " : "") + sentence;
    }
  }

  if (currentChunk) {
    chunks.push(currentChunk.trim());
  }

  return chunks;
}

/**
 * OpenAI ì„ë² ë”© ìƒì„±
 */
async function generateEmbedding(text: string): Promise<number[]> {
  try {
    const response = await openai.embeddings.create({
      model: "text-embedding-3-small",
      input: text,
      dimensions: 1536,
    });

    return response.data[0].embedding;
  } catch (error) {
    console.error("ì„ë² ë”© ìƒì„± ì‹¤íŒ¨:", error);
    throw error;
  }
}

interface TenantRecord {
  name: string;
  name_en?: string;
  specialty?: string;
  default_language?: string;
  system_prompt?: string;
  model?: string;
  confidence_threshold?: string;
  escalation_keywords?: string;
}

interface KnowledgeRecord {
  tenant_name: string;
  title: string;
  content: string;
  category?: string;
  tags?: string;
}

/**
 * ê±°ë˜ì²˜ CSV ë§ˆì´ê·¸ë ˆì´ì…˜
 */
async function migrateTenants(csvPath: string): Promise<void> {
  console.log("ğŸ“Š ê±°ë˜ì²˜ CSV ì½ê¸°:", csvPath);

  const csvContent = fs.readFileSync(csvPath, "utf-8");
  const records = parse(csvContent, {
    columns: true,
    skip_empty_lines: true,
    trim: true,
  }) as TenantRecord[];

  console.log(`âœ… ${records.length}ê°œ ê±°ë˜ì²˜ ë°œê²¬`);

  let successCount = 0;
  let errorCount = 0;

  for (const record of records) {
    try {
      const tenantData = {
        name: record.name,
        name_en: record.name_en || null,
        specialty: record.specialty || null,
        default_language: record.default_language || "ko",
        ai_config: {
          system_prompt: record.system_prompt || null,
          model: record.model || "gpt-4",
          confidence_threshold: parseFloat(record.confidence_threshold || "0.75"),
          escalation_keywords: record.escalation_keywords
            ? record.escalation_keywords.split(",").map((k: string) => k.trim())
            : [],
        },
        settings: {},
      };

      const { data, error } = await supabase
        .from("tenants")
        .insert(tenantData)
        .select()
        .single();

      if (error) {
        console.error(`âŒ [${record.name}] ì €ì¥ ì‹¤íŒ¨:`, error.message);
        errorCount++;
      } else {
        console.log(`âœ… [${record.name}] ì €ì¥ ì™„ë£Œ (ID: ${data.id})`);
        successCount++;
      }
    } catch (err: any) {
      console.error(`âŒ [${record.name}] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:`, err.message);
      errorCount++;
    }
  }

  console.log(`\nğŸ“Š ê±°ë˜ì²˜ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ:`);
  console.log(`  - ì„±ê³µ: ${successCount}ê°œ`);
  console.log(`  - ì‹¤íŒ¨: ${errorCount}ê°œ`);
}

/**
 * ì§€ì‹ë² ì´ìŠ¤ CSV ë§ˆì´ê·¸ë ˆì´ì…˜ (ë²¡í„° ì„ë² ë”© í¬í•¨)
 */
async function migrateKnowledge(csvPath: string): Promise<void> {
  console.log("ğŸ“Š ì§€ì‹ë² ì´ìŠ¤ CSV ì½ê¸°:", csvPath);

  const csvContent = fs.readFileSync(csvPath, "utf-8");
  const records = parse(csvContent, {
    columns: true,
    skip_empty_lines: true,
    trim: true,
  }) as KnowledgeRecord[];

  console.log(`âœ… ${records.length}ê°œ ì§€ì‹ ë¬¸ì„œ ë°œê²¬`);

  // ê±°ë˜ì²˜ëª… â†’ ID ë§¤í•‘
  const { data: tenants } = await supabase.from("tenants").select("id, name");
  const tenantMap = new Map<string, string>();
  (tenants || []).forEach((t: any) => {
    tenantMap.set(t.name, t.id);
  });

  let successCount = 0;
  let errorCount = 0;
  let embeddingCount = 0;

  for (const record of records) {
    try {
      const tenantId = tenantMap.get(record.tenant_name);

      if (!tenantId) {
        console.error(`âŒ [${record.title}] ê±°ë˜ì²˜ "${record.tenant_name}"ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.`);
        errorCount++;
        continue;
      }

      // 1. ë¬¸ì„œ ì €ì¥
      const docData = {
        tenant_id: tenantId,
        title: record.title,
        content: record.content,
        category: record.category || null,
        tags: record.tags ? record.tags.split(",").map((t: string) => t.trim()) : [],
        is_active: true,
      };

      const { data: doc, error: docError } = await supabase
        .from("knowledge_documents")
        .insert(docData)
        .select()
        .single();

      if (docError) {
        console.error(`âŒ [${record.title}] ë¬¸ì„œ ì €ì¥ ì‹¤íŒ¨:`, docError.message);
        errorCount++;
        continue;
      }

      console.log(`âœ… [${record.title}] ë¬¸ì„œ ì €ì¥ ì™„ë£Œ (ID: ${doc.id})`);
      successCount++;

      // 2. í…ìŠ¤íŠ¸ ì²­í‚¹
      const chunks = chunkText(record.content, 500);
      console.log(`   ğŸ“„ ${chunks.length}ê°œ ì²­í¬ ìƒì„±`);

      // 3. ê° ì²­í¬ì— ëŒ€í•´ ì„ë² ë”© ìƒì„± ë° ì €ì¥
      for (let i = 0; i < chunks.length; i++) {
        const chunkText = chunks[i];

        try {
          // ì„ë² ë”© ìƒì„±
          const embedding = await generateEmbedding(chunkText);

          // knowledge_chunks í…Œì´ë¸”ì— ì €ì¥
          const { error: chunkError } = await supabase.from("knowledge_chunks").insert({
            document_id: doc.id,
            chunk_index: i,
            chunk_text: chunkText,
            embedding: JSON.stringify(embedding), // pgvector VECTOR íƒ€ì…ìœ¼ë¡œ ìë™ ë³€í™˜
          });

          if (chunkError) {
            console.error(`   âŒ ì²­í¬ ${i + 1} ì €ì¥ ì‹¤íŒ¨:`, chunkError.message);
          } else {
            embeddingCount++;
          }

          // Rate limiting: 100ms ëŒ€ê¸°
          await new Promise((resolve) => setTimeout(resolve, 100));
        } catch (embeddingError: any) {
          console.error(`   âŒ ì²­í¬ ${i + 1} ì„ë² ë”© ì‹¤íŒ¨:`, embeddingError.message);
        }
      }

      console.log(`   âœ… ${embeddingCount}ê°œ ì„ë² ë”© ì™„ë£Œ\n`);
    } catch (err: any) {
      console.error(`âŒ [${record.title}] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:`, err.message);
      errorCount++;
    }
  }

  console.log(`\nğŸ“Š ì§€ì‹ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ:`);
  console.log(`  - ë¬¸ì„œ ì„±ê³µ: ${successCount}ê°œ`);
  console.log(`  - ë¬¸ì„œ ì‹¤íŒ¨: ${errorCount}ê°œ`);
  console.log(`  - ì„ë² ë”© ìƒì„±: ${embeddingCount}ê°œ`);
}

/**
 * ë©”ì¸ ì‹¤í–‰
 */
async function main() {
  const args = process.argv.slice(2);

  let type = "tenants";
  let file = "";

  for (let i = 0; i < args.length; i++) {
    if (args[i] === "--type") {
      type = args[i + 1];
      i++;
    } else if (args[i] === "--file") {
      file = args[i + 1];
      i++;
    }
  }

  if (!file) {
    console.error("âŒ --file ì˜µì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤.");
    console.log("\nì‚¬ìš©ë²•:");
    console.log("  npm run migrate:csv -- --type tenants --file tenants.csv");
    console.log("  npm run migrate:csv -- --type knowledge --file knowledge.csv");
    process.exit(1);
  }

  const csvPath = path.resolve(process.cwd(), file);

  if (!fs.existsSync(csvPath)) {
    console.error(`âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${csvPath}`);
    process.exit(1);
  }

  console.log("ğŸš€ CSV ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘\n");
  console.log(`  - íƒ€ì…: ${type}`);
  console.log(`  - íŒŒì¼: ${csvPath}\n`);

  if (type === "tenants") {
    await migrateTenants(csvPath);
  } else if (type === "knowledge") {
    await migrateKnowledge(csvPath);
  } else {
    console.error(`âŒ ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì…: ${type}`);
    console.log("  ì§€ì›ë˜ëŠ” íƒ€ì…: tenants, knowledge");
    process.exit(1);
  }

  console.log("\nâœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!");
}

main().catch((error) => {
  console.error("âŒ ì¹˜ëª…ì  ì˜¤ë¥˜:", error);
  process.exit(1);
});
